{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866aa8d0",
   "metadata": {},
   "source": [
    "title: Customer Snapshots split test\n",
    "\n",
    "author: Nimi Thomas\n",
    "\n",
    "date: 2021-06-24\n",
    "\n",
    "region: EU  \n",
    "\n",
    "tags: assistance, eu, ab, split\n",
    "\n",
    "summary:  Customer snapshots is a DASH26 module which shows the most accessed user information in just one view. This one module shows an aggregated view of multiple modules including customer information on; personal details, account, kyc, cards and transactions. We want to know if DASH26 improvements alone can improve handling times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab219c5",
   "metadata": {},
   "source": [
    "# Customer Snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548614bc",
   "metadata": {},
   "source": [
    "### Contents \n",
    "1. [Background](#section1)  \n",
    "2. [Current Metrics](#section2)  \n",
    "3. [Hypothesis](#section3)  \n",
    "4. [Experimental Design](#section4) \n",
    "5. [Statistical Analysis](#section5)\n",
    "6. [Final Results](#section6)\n",
    "    - a) [Overall](#section6a)\n",
    "    - b) [Tag split](#section6b)\n",
    "    - c) [Chat Origin](#section6c)\n",
    "    - d) [Tenure split](#section6d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b80b22",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28da490",
   "metadata": {},
   "source": [
    "This initiative is the result of [user surveys](https://docs.google.com/spreadsheets/d/17hrHuZmNRnJeG9Pn24Im3Aa2lWFIJlbV0GcFX9L7zKI/edit?usp=sharing) on the performance of DASH26 which highlighted the importance for consolidated customer data. \n",
    "\n",
    "For the vast majority of contacts processed by Customer Service, only a small fraction of the data available in Dash26 to first-level specialists is actually required to resolve a contact. This data is scattered across multiple modules and tabs, resulting in unnecessarily long loading times and thus longer contact resolution times.\n",
    "\n",
    "Our goal is to remove unnecessary clicks, navigation and loading time by consolidating most of the necessary data into a “snapshot” of the customer. This should provide specialists with quicker access to the data they need and resolve the majority of contacts faster. \n",
    "\n",
    "There are certain CS tags that may be more relevant to this feature including: \n",
    "'sign_up','kyc_acceptance','card_delivery','card_activation/pin','login', 'confirmations/statements','dt/standing_order','ct/missing_ct','direct_debit', 'instant_ct_/missing_ct','instant_dt','savings','overdraft' since most of the information the agent needs for these sort of contacts will be in the snapshot feature.\n",
    "\n",
    "For more info check out this confluence page [here](https://number26-jira.atlassian.net/wiki/spaces/CS/pages/2376532754/Customer+Snapshot+in+Dash26).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ef571",
   "metadata": {},
   "source": [
    "### TLDR \n",
    "Customer snapshots is a DASH26 module which shows the most accessed user information in just one view. This one module shows an aggregated view of multiple modules including customer information on; personal details, account, kyc, cards and transactions. We want to know if DASH26 improvements alone can improve handling times.\n",
    "\n",
    "### Findings\n",
    "\n",
    "- The overall results did show significant evidence to prove a small decrease in handle times (10-20 seconds) in the group of tags we aimed to target. \n",
    "- When we drilled down by specific tags within this group, our results were inconclusive. The only significant result seemed to be for tag sign_up and this only makes up 6% of our specific tags group. We have to acknowledge we have smaller sample sizes when we drill down results further. The Snapshot module does not seem to benefit on a tag level so there may be other contributing factors.\n",
    "- When we drilled down by chat origin we saw there was a significant result for Support Center chats. Agents handling contacts from Support Center may benefit from the Customer Snapshots module since generic customer information may be required for authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1646a8",
   "metadata": {},
   "source": [
    "### Limitations \n",
    "\n",
    "Handle time is made up of time chatting to a customer (Salesforce time), time investigating (DASH time) and wrap up.\n",
    "\n",
    "Due to a lack of DASH tracking we are unable to track which agents actually use the new feature in the variant group of the split test. We also cannot track the total time actively in DASH. We are planning to add snowplow tracking in the near future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e86a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2b733031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import display_html\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, beta, wilcoxon\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from utils.datalib_database import df_from_sql\n",
    "from utils.helper_functions import get_data\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2ad6760b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handled_contacts = df_from_sql(\n",
    "    \"redshiftreader\",\n",
    "    \"\"\" \n",
    "    select \n",
    "        a.initiated_date::date as date, \n",
    "        date_trunc('week',a.initiated_date)::date as week,\n",
    "        coalesce(s.chat_origin,'unknown') as chat_origin,\n",
    "        left(a.specialist_id,15) as specialist_id,\n",
    "        specialist_tenure_months,\n",
    "        a.cs_tag as tag_name,\n",
    "        case \n",
    "        \twhen a.cs_tag = 'wise' then 'Payments' \n",
    "        \twhen segment like 'Bank Products%' then 'Bank Products'\n",
    "   \t\telse coalesce(segment, 'Other')\n",
    "    \tend as tag_group,\n",
    "        a.contact_language, \n",
    "        a.company_general,\n",
    "        u.tnc_country_group, \n",
    "        case \n",
    "            when a.cs_tag in (\n",
    "                'sign_up','kyc_acceptance','card_delivery','card_activation/pin','login',\n",
    "                'confirmations/statements','dt/standing_order','ct/missing_ct','direct_debit',\n",
    "                'instant_ct_/missing_ct','instant_dt','savings','overdraft')\n",
    "            then true else false \n",
    "        end as customer_snapshot_specific_tag, \n",
    "        handle_time/60 as handle_time_minutes\n",
    "    from dbt.sf_all_contacts a \n",
    "    inner join dbt.sf_chat_summary s \n",
    "        on a.id = s.id\n",
    "    left join dbt.ucm_cs_mapping cs\n",
    "    \ton a.cs_tag = cs.tag_name\n",
    "    left join dbt.zrh_users u \n",
    "        on a.user_id = u.user_id\n",
    "    where 1=1\n",
    "    and a.contact_date is not null \n",
    "    and a.abandoned is false\n",
    "    and a.handle_time > 0\n",
    "    and a.channel_type = '1st level'\n",
    "    and a.initiated_date >= '2021-04-05' -- from first full week in April\n",
    "    and a.initiated_date < '2021-06-21' -- test runs for 2-3 weeks in June\n",
    "    and (tnc_country_group <> 'GBR' or tnc_country_group is null)  -- handful of contacts\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25fdc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "handled_contacts[\"specialist_tenure_months\"] = pd.to_numeric(\n",
    "    handled_contacts[\"specialist_tenure_months\"]\n",
    ")\n",
    "handled_contacts[\"tenure_bins\"] = pd.qcut(\n",
    "    handled_contacts[\"specialist_tenure_months\"], q=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9887dec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_groups = get_data(\n",
    "    \"19eND4rsQfdcMa9bc3K5lXIYlVjenfyNTy7fsNlZYGDw\",\n",
    "    \"Final List!A1:J1\",\n",
    "    \"Final List!A2:J10000000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95185cd6",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Current Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1e5ff128",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = pd.crosstab(\n",
    "    handled_contacts.week, handled_contacts.customer_snapshot_specific_tag\n",
    ").plot.bar(stacked=True, figsize=(20, 5))\n",
    "\n",
    "for c in stacked.containers:\n",
    "    stacked.bar_label(c, label_type=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab101e",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Volumes of 1st level chats can vary week on week. So we'll have to monitor how much volume we get as the A/B test is rolled out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce2a3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    handled_contacts.week, handled_contacts.handle_time_minutes, ax=ax\n",
    ").set_title(\"Handle Time(minutes) percentiles\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877b047",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Percentiles for Handle Time minutes stays roughly constant over weeks. The median roughly sits around 10-12 minutes. \n",
    "\n",
    "Note since we're dealing with a continuous variable(time) we can see quite a few outliers in the data which exceed past the 95th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e110c",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## Hypothesis\n",
    "\n",
    "Investigation time in Dash26 will be reduced with more easily accessible customer data via Customer Snapchats module thus impacting the overall 1st Level chat handling times. \n",
    "\n",
    "H0 : there is no significant difference between 1st Level handling times \n",
    "\n",
    "H1 : the 1st Level handling time of the test group is significantly less than the control group. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b8a7e",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386ba9a",
   "metadata": {},
   "source": [
    "Specialists will be split based on language, company and tenure. \n",
    "\n",
    "**A** group is the control; they will see the current version of DASH26. \n",
    "\n",
    "**B** group is the variant; they will see the customer snapshots module in DASH26. \n",
    "\n",
    "The A/B testing will be implemented from **2021-06-01**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46bad865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge handle times with A/B groups\n",
    "handled_contacts_split = pd.merge(\n",
    "    handled_contacts, split_groups, how=\"inner\", on=[\"specialist_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91d830ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "handled_contacts_split[\"date\"] = pd.to_datetime(\n",
    "    handled_contacts_split[\"date\"], format=\"%Y/%m/%d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "391109af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\\033[1m\" + \"Specialist split in test/ dbt.sf_all_contacts from 2021-06-01 onwards\"\n",
    ")\n",
    "\n",
    "handled_contacts_split[(handled_contacts_split.date > \"2021-05-31\")].groupby(\n",
    "    [\"Languages\", \"Company_Group\", \"test_group\"]\n",
    ")[\"specialist_id\"].nunique().unstack(\"test_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "feeaf689",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Handle Time quantiles 3 months before split test\")\n",
    "past_handled_contacts = handled_contacts_split[\n",
    "    (handled_contacts_split.date < \"2021-05-31\")\n",
    "]\n",
    "past_handled_contacts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36b0d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "vio_split = sns.violinplot(\n",
    "    past_handled_contacts.week,\n",
    "    past_handled_contacts.handle_time_minutes,\n",
    "    hue=handled_contacts_split[\"test_group\"],\n",
    "    split=True,\n",
    ")\n",
    "vio_split.set_title(\n",
    "    \"Distribution of handle time minutes split by experiment groups\", fontsize=16\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0895d",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> The distribution of 1st Level chat handle times seem to be right skewed.\n",
    "\n",
    "We have to acknowledge that we do have many outliers in our distribution. This may make it difficult to compare means between A and B groups under the more common statistical tests for normal distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61e42c0",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d476c",
   "metadata": {},
   "source": [
    "**Independent variable** : Dash26 version (binary), agent split by language (categorical) ,company (categorical) and tenure(continuous). \n",
    "\n",
    "**Dependant variable** : 1st Level handle time (continuous/ right skewed with many outlier)\n",
    "\n",
    "**Statistical Test** : Mann-Whitney test (aka the Wilcoxon 2-sample Test) which compares the medians/rank sums from two populations and works when the Y variable is continuous. It is much more robust against outliers and heavy tail distributions. \n",
    "\n",
    "**Type I Error** : Significance level, α = 0.05\n",
    "\n",
    "<font color='grey'> **Type II Error** : β = 0.2 </font> \n",
    "\n",
    "**Power** : The Mann Whitney test is under powered in general so the chances of a false positive is quite low. This means if we find a significant result, we can be somewhat confident that it's significant/reflects reality. \n",
    "\n",
    "<font color='grey'>(**Standard Power** : 1 – β = 1 – 0.2 = 0.8)</font>  \n",
    "\n",
    "**Hypothesis** - one tailed test: \n",
    "\n",
    "H0: the distributions of both samples are equal\n",
    "\n",
    "H1: the distributions of the variant sample is lower than the control's  (lower-tailed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437bce5",
   "metadata": {},
   "source": [
    "### Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f4f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Mann Whitney function for different dataframes input\n",
    "\n",
    "\n",
    "def mann_whiteney_test(\n",
    "    df, df_text, time_frequency, alternative, alpha, cumulative=False\n",
    "):\n",
    "    for i in df[time_frequency].unique():\n",
    "        if cumulative == True:\n",
    "            control = df[(df[\"Group (A/B)\"] == \"A\") & (df[time_frequency] <= i)][\n",
    "                \"handle_time_minutes\"\n",
    "            ]\n",
    "            variant = df[(df[\"Group (A/B)\"] == \"B\") & (df[time_frequency] <= i)][\n",
    "                \"handle_time_minutes\"\n",
    "            ]\n",
    "        else:\n",
    "            control = df[(df[\"Group (A/B)\"] == \"A\") & (df[time_frequency] == i)][\n",
    "                \"handle_time_minutes\"\n",
    "            ]\n",
    "            variant = df[(df[\"Group (A/B)\"] == \"B\") & (df[time_frequency] == i)][\n",
    "                \"handle_time_minutes\"\n",
    "            ]\n",
    "\n",
    "        stat, p = mannwhitneyu(variant, control, alternative=alternative)\n",
    "\n",
    "        # interpret\n",
    "        if p > alpha:\n",
    "            mannwhiteney_list.append(\n",
    "                [\n",
    "                    i,\n",
    "                    df_text,\n",
    "                    p,\n",
    "                    \"Samples have similar distributions (fail to reject H0)\",\n",
    "                ]\n",
    "            )\n",
    "            # print('Same distribution (fail to reject H0)')\n",
    "        else:\n",
    "            mannwhiteney_list.append(\n",
    "                [\n",
    "                    i,\n",
    "                    df_text,\n",
    "                    p,\n",
    "                    f\"Variant time distribution is significantly different ({alternative}) (reject H0)\",\n",
    "                ]\n",
    "            )\n",
    "            # print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb536d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_tags = past_handled_contacts[\n",
    "    past_handled_contacts[\"customer_snapshot_specific_tag\"] == True\n",
    "]\n",
    "\n",
    "mannwhiteney_list = []\n",
    "\n",
    "mann_whiteney_test(\n",
    "    past_handled_contacts, \"all tags\", \"week\", \"two-sided\", 0.025, cumulative=True\n",
    ")\n",
    "mann_whiteney_test(\n",
    "    specific_tags, \"specific tags\", \"week\", \"two-sided\", 0.025, cumulative=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4736676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(\n",
    "    \"\\033[1m\"\n",
    "    + \"Weekly Mann Whiteney U test on historical handle time quantiles 2 months before split test\"\n",
    ")\n",
    "\n",
    "mannwhiteney = pd.DataFrame(\n",
    "    mannwhiteney_list, columns=[\"week\", \"test\", \"p_value\", \"result\"]\n",
    ")\n",
    "mannwhiteney.groupby([\"week\", \"test\"]).min().unstack(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658cc4e",
   "metadata": {},
   "source": [
    "### Stratify to control for differences between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5098bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get group splits across all contacts\n",
    "\n",
    "stratified_df = (\n",
    "    handled_contacts[\"tnc_country_group\"]\n",
    "    + \" - \"\n",
    "    + handled_contacts[\"company_general\"]\n",
    "    + \" - \"\n",
    "    + handled_contacts[\"chat_origin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c47fbace",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_df = (stratified_df.value_counts(normalize=True)).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "26b7b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "handled_contacts_split[\"stratify\"] = (\n",
    "    handled_contacts_split[\"tnc_country_group\"]\n",
    "    + \" - \"\n",
    "    + handled_contacts_split[\"company_general\"]\n",
    "    + \" - \"\n",
    "    + handled_contacts[\"chat_origin\"]\n",
    ")\n",
    "\n",
    "control = handled_contacts_split[(handled_contacts_split[\"Group (A/B)\"] == \"A\")]\n",
    "variant = handled_contacts_split[(handled_contacts_split[\"Group (A/B)\"] == \"B\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b9cebb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_data(\n",
    "    df_data,\n",
    "    stratify_column_name,\n",
    "    stratify_values,\n",
    "    stratify_proportions,\n",
    "    random_state=None,\n",
    "):\n",
    "    \"\"\"Stratifies data according to the values and proportions passed in\n",
    "    Args:\n",
    "        df_data (DataFrame): source data\n",
    "        stratify_column_name (str): The name of the single column in the dataframe that holds the data values that will be used to stratify the data\n",
    "        stratify_values (list of str): A list of all of the potential values for stratifying e.g. \"Male, Graduate\", \"Male, Undergraduate\", \"Female, Graduate\", \"Female, Undergraduate\"\n",
    "        stratify_proportions (list of float): A list of numbers representing the desired propotions for stratifying e.g. 0.4, 0.4, 0.2, 0.2, The list values must add up to 1 and must match the number of values in stratify_values\n",
    "        random_state (int, optional): sets the random_state. Defaults to None.\n",
    "    Returns:\n",
    "        DataFrame: a new dataframe based on df_data that has the new proportions represnting the desired strategy for stratifying\n",
    "    \"\"\"\n",
    "    df_stratified = pd.DataFrame(\n",
    "        columns=df_data.columns\n",
    "    )  # Create an empty DataFrame with column names matching df_data\n",
    "\n",
    "    pos = -1\n",
    "    for i in range(\n",
    "        len(stratify_values)\n",
    "    ):  # iterate over the stratify values (e.g. \"Male, Undergraduate\" etc.)\n",
    "        pos += 1\n",
    "        if pos == len(stratify_values) - 1:\n",
    "            ratio_len = len(df_data) - len(\n",
    "                df_stratified\n",
    "            )  # if this is the final iteration make sure we calculate the number of values for the last set such that the return data has the same number of rows as the source data\n",
    "        else:\n",
    "            ratio_len = int(\n",
    "                len(df_data) * stratify_proportions[i]\n",
    "            )  # Calculate the number of rows to match the desired proportion\n",
    "\n",
    "        df_filtered = df_data[\n",
    "            df_data[stratify_column_name] == stratify_values[i]\n",
    "        ]  # Filter the source data based on the currently selected stratify value\n",
    "\n",
    "        try:\n",
    "            df_temp = df_filtered.sample(\n",
    "                replace=False, n=ratio_len, random_state=random_state\n",
    "            )  # Sample the filtered data using the calculated ratio\n",
    "        except:\n",
    "            df_temp = df_filtered  # pd.DataFrame() # when sample size is small, take the empty/small filtered datframe\n",
    "\n",
    "        df_stratified = pd.concat(\n",
    "            [df_stratified, df_temp]\n",
    "        )  # Add the sampled / stratified datasets together to produce the final result\n",
    "\n",
    "    return df_stratified  # Return the stratified, re-sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cb74a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_stratified = stratify_data(\n",
    "    control,\n",
    "    \"stratify\",\n",
    "    stratified_df.iloc[:, 0],\n",
    "    stratified_df.iloc[:, 1],\n",
    "    random_state=1,\n",
    ")\n",
    "variant_stratified = stratify_data(\n",
    "    variant,\n",
    "    \"stratify\",\n",
    "    stratified_df.iloc[:, 0],\n",
    "    stratified_df.iloc[:, 1],\n",
    "    random_state=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cbbde630",
   "metadata": {},
   "outputs": [],
   "source": [
    "handled_contacts_strat = control_stratified.append([variant_stratified])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "87f3241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total removed rows:\")\n",
    "handled_contacts_split.shape[0] - handled_contacts_strat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0c8ca291",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_handled_contacts_strat = handled_contacts_strat[\n",
    "    (handled_contacts_strat.date < \"2021-05-31\")\n",
    "]\n",
    "specific_tags_strat = past_handled_contacts_strat[\n",
    "    past_handled_contacts_strat[\"customer_snapshot_specific_tag\"] == True\n",
    "]\n",
    "other_tags_strat = past_handled_contacts_strat[\n",
    "    past_handled_contacts_strat[\"customer_snapshot_specific_tag\"] == False\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0e660fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhiteney_list = []\n",
    "\n",
    "mann_whiteney_test(\n",
    "    past_handled_contacts_strat, \"all tags\", \"week\", \"two-sided\", 0.025, cumulative=True\n",
    ")\n",
    "mann_whiteney_test(\n",
    "    specific_tags_strat, \"specific tags\", \"week\", \"two-sided\", 0.025, cumulative=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fff58deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(\n",
    "    \"\\033[1m\"\n",
    "    + \"Cumulative weekly Mann Whiteney U test on historical handle time quantiles 3 months before split test\"\n",
    ")\n",
    "\n",
    "mannwhiteney = pd.DataFrame(\n",
    "    mannwhiteney_list, columns=[\"week\", \"test\", \"p_value\", \"result\"]\n",
    ")\n",
    "mannwhiteney.groupby([\"week\", \"test\"]).min().unstack(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bffb26a",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc25fac",
   "metadata": {},
   "source": [
    "There was an incident in DASH26 on the first day of release, so we will exclude 2021-06-01 from results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f42dfc",
   "metadata": {},
   "source": [
    "<a id='section6a'></a>\n",
    "### Overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "97a54e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_handled_contacts = handled_contacts_strat[\n",
    "    handled_contacts_strat.date > \"2021-06-01\"\n",
    "]\n",
    "final_specific_tags = final_handled_contacts[\n",
    "    final_handled_contacts[\"customer_snapshot_specific_tag\"] == True\n",
    "]\n",
    "final_other_tags = final_handled_contacts[\n",
    "    final_handled_contacts[\"customer_snapshot_specific_tag\"] == False\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3a8e2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of obs per group & median to position labels\n",
    "\n",
    "\n",
    "def box_plot_with_n_label(df, order, title):\n",
    "    medians = df.groupby([\"test_group\"])[\"handle_time_minutes\"].median().values\n",
    "    nobs = df[\"test_group\"].value_counts().values\n",
    "    nobs = [str(x) for x in nobs.tolist()]\n",
    "    nobs = [\"n: \" + i for i in nobs]\n",
    "\n",
    "    # Add it to the plot\n",
    "    pos = range(len(nobs))\n",
    "    for tick, label in zip(pos, ax[order].get_xticklabels()):\n",
    "        ax[order].text(\n",
    "            pos[tick],\n",
    "            medians[tick] + 2,\n",
    "            nobs[tick],\n",
    "            horizontalalignment=\"center\",\n",
    "            size=\"small\",\n",
    "            color=\"w\",\n",
    "            weight=\"semibold\",\n",
    "        )\n",
    "\n",
    "    sns.boxplot(\n",
    "        df[\"test_group\"],\n",
    "        df.handle_time_minutes,\n",
    "        ax=ax[order],\n",
    "        order=[\"control\", \"variant\"],\n",
    "    ).set_title(title, fontsize=16);\n",
    "    # sns.boxplot(final_specific_tags[\"Group (A/B)\"], final_specific_tags.handle_time_minutes, ax=ax[1]).set_title('Specific Tags Handle Time(minutes) percentiles', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "aaaf5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7))\n",
    "\n",
    "box_plot_with_n_label(final_handled_contacts, 0, \"Handle Time(minutes) percentiles\")\n",
    "box_plot_with_n_label(\n",
    "    final_specific_tags, 1, \"Specific Tags Handle Time(minutes) percentiles\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ac6659d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (\n",
    "    final_handled_contacts[[\"handle_time_minutes\", \"Group (A/B)\"]]\n",
    "    .groupby(\"Group (A/B)\")\n",
    "    .describe()\n",
    "    .unstack(1)\n",
    "    .reset_index()\n",
    "    .pivot(index=\"Group (A/B)\", values=0, columns=\"level_1\")\n",
    ")\n",
    "df2 = (\n",
    "    final_specific_tags[[\"handle_time_minutes\", \"Group (A/B)\"]]\n",
    "    .groupby(\"Group (A/B)\")\n",
    "    .describe()\n",
    "    .unstack(1)\n",
    "    .reset_index()\n",
    "    .pivot(index=\"Group (A/B)\", values=0, columns=\"level_1\")\n",
    ")\n",
    "\n",
    "df1_styler = df1.style.set_table_attributes(\"style='display:inline'\").set_caption(\n",
    "    \"All tags\"\n",
    ")\n",
    "df2_styler = df2.style.set_table_attributes(\"style='display:inline'\").set_caption(\n",
    "    \"Specific tags\"\n",
    ")\n",
    "\n",
    "display_html(df1_styler._repr_html_() + df2_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4614ca",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Visually there's not much difference in handle time overall or for our specific tags group between control and variant. From the final figures there is a 10-20 seconds decrease from the control's to variant's median in the specific tags group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7ea0cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhiteney_list = []\n",
    "mann_whiteney_test(\n",
    "    final_handled_contacts, \"all tags\", \"date\", \"less\", 0.05, cumulative=True\n",
    ")\n",
    "mann_whiteney_test(\n",
    "    final_specific_tags, \"specific tags\", \"date\", \"less\", 0.05, cumulative=True\n",
    ")\n",
    "mannwhiteney_cumulative = pd.DataFrame(\n",
    "    mannwhiteney_list, columns=[\"date\", \"test\", \"p_value\", \"result\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b9e35b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_plot = (\n",
    "    mannwhiteney_cumulative.groupby([\"date\", \"test\"])[\"p_value\"].min().unstack(\"test\")\n",
    ")\n",
    "p_val_plot[\"alpha; reject null hypothesis area\"] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "55d4766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_val_plot.plot(figsize=(20, 5)).set_title(\n",
    "    \"Cumulative Mann Whiteney Test - p value\", fontsize=16\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d16519c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mannwhiteney_cumulative[\n",
    "    mannwhiteney_cumulative.date == mannwhiteney_cumulative[\"date\"].max()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc70d7",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Though the decrease is small for the specific tags group; ~2.24% decrease in the median and ~3.76% decrease in the 25th percentile, the result is significant using the Mann Whitney U test. The Snapshots Module feature does not impact the overall handle time distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f13995",
   "metadata": {},
   "source": [
    "<a id='section6b'></a>\n",
    "### Tag split\n",
    "#### Specific Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091e685",
   "metadata": {},
   "source": [
    "We had the assumption that the Customer Snapshots module is more relevent to certain CS tags:\n",
    "- card_activation/pin\n",
    "- card_delivery\n",
    "- confirmations/statements\n",
    "- ct/missing_ct\n",
    "- direct_debit\n",
    "- dt/standing_order\n",
    "- instant_ct_/missing_ct\n",
    "- instant_dt\n",
    "- kyc_acceptance\n",
    "- login\n",
    "- overdraft\n",
    "- savings\n",
    "- sign_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "96279ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative daily Mann Whitney function for variable split\n",
    "def variable_mann_whiteney_test(df, variable):\n",
    "    for date in df[\"date\"].unique():\n",
    "        for i in df[variable].unique():\n",
    "            control = df[\n",
    "                (df[\"Group (A/B)\"] == \"A\") & (df[\"date\"] <= date) & (df[variable] == i)\n",
    "            ][\"handle_time_minutes\"]\n",
    "            variant = df[\n",
    "                (df[\"Group (A/B)\"] == \"B\") & (df[\"date\"] <= date) & (df[variable] == i)\n",
    "            ][\"handle_time_minutes\"]\n",
    "\n",
    "            try:\n",
    "                stat, p = mannwhitneyu(variant, control, alternative=\"less\")\n",
    "\n",
    "                # interpret\n",
    "                alpha = 0.05\n",
    "\n",
    "                if p > alpha:\n",
    "                    cumulative_tag_list.append(\n",
    "                        [\n",
    "                            date,\n",
    "                            len(control.index),\n",
    "                            len(variant.index),\n",
    "                            i,\n",
    "                            p,\n",
    "                            \"Samples have similar distributions (fail to reject H0)\",\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    cumulative_tag_list.append(\n",
    "                        [\n",
    "                            date,\n",
    "                            len(control.index),\n",
    "                            len(variant.index),\n",
    "                            i,\n",
    "                            p,\n",
    "                            \"Variant time distribution is significantly lower than the control (reject H0)\",\n",
    "                        ]\n",
    "                    )\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "228ae769",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_tag_list = []\n",
    "variable_mann_whiteney_test(specific_tags_strat, \"tag_name\")\n",
    "mannwhiteney_cumulative_tags = pd.DataFrame(\n",
    "    cumulative_tag_list,\n",
    "    columns=[\"date\", \"control size\", \"variant size\", \"tag_name\", \"p_value\", \"result\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0dbe4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Historicals\")\n",
    "\n",
    "mannwhiteney_cumulative_tags[\n",
    "    mannwhiteney_cumulative_tags.date == mannwhiteney_cumulative_tags[\"date\"].max()\n",
    "].sort_values(by=[\"control size\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f7784772",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_tag_list = []\n",
    "variable_mann_whiteney_test(final_specific_tags, \"tag_name\")\n",
    "mannwhiteney_cumulative_tags = pd.DataFrame(\n",
    "    cumulative_tag_list,\n",
    "    columns=[\"date\", \"control size\", \"variant size\", \"tag_name\", \"p_value\", \"result\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4c3baaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Experiment results\")\n",
    "\n",
    "mannwhiteney_cumulative_tags[\n",
    "    mannwhiteney_cumulative_tags.date == mannwhiteney_cumulative_tags[\"date\"].max()\n",
    "].sort_values(by=[\"control size\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357f416",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Looking at per tag in the specific tags group, there doesn't seem to be sufficient evidence to prove a decrease in handle time distribution. Results are inconclusive. Tag sign_up was the only significant result, but the sample size is smaller and we have to question whether the snapshot module really does benefit this tag.\n",
    "\n",
    "Note: We have to acknowledge that we would have had to run the test for much longer if we wanted further breakdowns, we can already see the sample size is small for some of these tag names at the end of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c7cec",
   "metadata": {},
   "source": [
    "<a id='section6c'></a>\n",
    "### Chat origin split\n",
    "\n",
    "Assumption: Contacts from support center may benefit from the customer snapshots since generic customer information may be required for authentication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "379d7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_tag_list = []\n",
    "variable_mann_whiteney_test(past_handled_contacts_strat, \"chat_origin\")\n",
    "mannwhiteney_cumulative_tags = pd.DataFrame(\n",
    "    cumulative_tag_list,\n",
    "    columns=[\n",
    "        \"date\",\n",
    "        \"control size\",\n",
    "        \"variant size\",\n",
    "        \"chat_origin\",\n",
    "        \"p_value\",\n",
    "        \"result\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "94ff106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Historicals\")\n",
    "\n",
    "mannwhiteney_cumulative_tags[\n",
    "    mannwhiteney_cumulative_tags.date == mannwhiteney_cumulative_tags[\"date\"].max()\n",
    "].sort_values(by=[\"control size\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3e4a9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_tag_list = []\n",
    "variable_mann_whiteney_test(final_handled_contacts, \"chat_origin\")\n",
    "mannwhiteney_cumulative_tags = pd.DataFrame(\n",
    "    cumulative_tag_list,\n",
    "    columns=[\n",
    "        \"date\",\n",
    "        \"control size\",\n",
    "        \"variant size\",\n",
    "        \"chat_origin\",\n",
    "        \"p_value\",\n",
    "        \"result\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "22bcffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Experiment results\")\n",
    "\n",
    "mannwhiteney_cumulative_tags[\n",
    "    mannwhiteney_cumulative_tags.date == mannwhiteney_cumulative_tags[\"date\"].max()\n",
    "].sort_values(by=[\"chat_origin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67326236",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Looking at chat origin groups, there is sufficient evidence to prove a decrease in handle time distribution specifically for Support Center contacts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c81e92",
   "metadata": {},
   "source": [
    "<a id='section6d'></a>\n",
    "### Tenure split\n",
    "\n",
    "Assumption : newer agents don't have a set way of working and we may see the impact of the snapshot module more prevalent here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fee05f55",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_tag_list = []\n",
    "variable_mann_whiteney_test(past_handled_contacts_strat, \"tenure_bins\")\n",
    "mannwhiteney_cumulative_tags = pd.DataFrame(\n",
    "    cumulative_tag_list,\n",
    "    columns=[\n",
    "        \"date\",\n",
    "        \"control size\",\n",
    "        \"variant size\",\n",
    "        \"tenure_bins\",\n",
    "        \"p_value\",\n",
    "        \"result\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "213b21c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Historicals\")\n",
    "\n",
    "mannwhiteney_cumulative_tags[\n",
    "    mannwhiteney_cumulative_tags.date == mannwhiteney_cumulative_tags[\"date\"].max()\n",
    "].sort_values(by=[\"tenure_bins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "524a8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_tag_list = []\n",
    "variable_mann_whiteney_test(final_handled_contacts, \"tenure_bins\")\n",
    "mannwhiteney_cumulative_tags = pd.DataFrame(\n",
    "    cumulative_tag_list,\n",
    "    columns=[\n",
    "        \"date\",\n",
    "        \"control size\",\n",
    "        \"variant size\",\n",
    "        \"tenure_bins\",\n",
    "        \"p_value\",\n",
    "        \"result\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "861f5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[1m\" + \"Experiment results\")\n",
    "\n",
    "mannwhiteney_cumulative_tags[\n",
    "    mannwhiteney_cumulative_tags.date == mannwhiteney_cumulative_tags[\"date\"].max()\n",
    "].sort_values(by=[\"tenure_bins\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7276f2",
   "metadata": {},
   "source": [
    "<font color='blue'>**Findings:**</font> Looking at tenure groups, there doesn't seem to be sufficient evidence to prove a decrease in handle time distribution. Results are inconclusive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
